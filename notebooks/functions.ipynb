{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNHzpaUKFcr1F7kjfcy4EDa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Functions\n","Disclaimer: todas as funções devem ser feitas em snake_case, sem abreviações, com docstring e exemplo (opcional)."],"metadata":{"id":"RZIFHhIYnNGP"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"7kEoTzkoabd5"}},{"cell_type":"code","source":["# analysis\n","import pandas as pd\n","import numpy as np\n","import glob\n","import json\n","import os\n","\n","# # define random seed of numpy\n","seed_value = 42\n","np.random.seed(seed_value)\n","\n","# plot\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as plx\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = [16, 4]\n","\n","# # progress\n","import traceback\n","from tqdm import tqdm\n","tqdm.pandas(desc=\"Processing Rows\")\n","\n","# # output\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# # forecast\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from pmdarima import auto_arima\n","from statsmodels.tsa.arima.model import ARIMA\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.stattools import adfuller\n","\n","# # expand display output\n","pd.set_option('display.max_columns', None)"],"metadata":{"id":"Ci97kevLadGd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Process"],"metadata":{"id":"2BjmtXMwqn_l"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vtyu-e6DnDh4"},"outputs":[],"source":["def processar_arquivos_csv(diretorio):\n","    \"\"\"\n","    Processa arquivos CSV em um diretório específico.\n","\n","    Parameters:\n","    - diretorio (str): O caminho do diretório que contém os arquivos CSV.\n","\n","    Returns:\n","    - data_frames (dict): Um dicionário contendo DataFrames tratados, onde as chaves são os nomes dos arquivos.\n","\n","    Example:\n","    >>> diretorio = \"../path/para/raw_data/\"\n","    >>> data_frames = processar_arquivos_csv(diretorio)\n","    >>> print(data_frames.keys())\n","    dict_keys(['nome_arquivo1', 'nome_arquivo2', ...])\n","    \"\"\"\n","    # Obtendo a lista de nomes de arquivo no diretório\n","    file_names = glob.glob(f\"{diretorio}/*\")\n","\n","    # Dicionário para armazenar os DataFrames tratados\n","    data_frames = {}\n","\n","    for file_name in file_names:\n","        # Obtendo o nome do arquivo sem a extensão\n","        name = file_name.split('/')[-1].split('.')[0]\n","\n","        # Lendo o arquivo CSV e aplicando os tratamentos\n","        df = pd.read_csv(file_name, sep=';')\n","        cols_to_keep = ['close', 'volume', 'marketCap', 'timestamp']\n","        cols_to_rename = {'timestamp': 'date', 'marketCap': 'market_cap'}\n","        df = df[cols_to_keep].rename(columns=cols_to_rename)\n","        df['date'] = pd.to_datetime(df['date'])\n","        df.set_index('date', inplace=True)\n","\n","        # Extrair o ticker da parte inicial do nome da chave\n","        ticker = name.split('_')[0]\n","\n","        # Adicionar a coluna 'ticker' ao DataFrame com o valor do ticker\n","        df['ticker'] = ticker\n","\n","        # Armazenando o DataFrame tratado no dicionário\n","        data_frames[name] = df\n","\n","    return data_frames"]},{"cell_type":"code","source":["def concatenar_dataframes(data_frames):\n","    \"\"\"\n","    Concatena DataFrames de um dicionário e remove possíveis duplicatas.\n","\n","    Parameters:\n","    - data_frames (dict): Um dicionário contendo DataFrames a serem concatenados.\n","\n","    Returns:\n","    - df_concatenado (pd.DataFrame): O DataFrame resultante após a concatenação e remoção de duplicatas.\n","\n","    Example:\n","    >>> data_frames = {'nome_arquivo1': df1, 'nome_arquivo2': df2, ...}\n","    >>> df_concatenado = concatenar_dataframes(data_frames)\n","    >>> print(df_concatenado.head())\n","       close  volume  market_cap  ticker\n","    date\n","    ...\n","    \"\"\"\n","    # Criar um DataFrame vazio para a concatenação\n","    df = pd.DataFrame()\n","\n","    # Concatenar todos os DataFrames no dicionário\n","    for value in data_frames.values():\n","        df = pd.concat([df, value])\n","\n","    # Remover possíveis duplicatas do DataFrame resultante\n","    df_concatenado = df.drop_duplicates()\n","\n","    return df_concatenado"],"metadata":{"id":"H0iRkKqwneGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def formatar_data(df):\n","    \"\"\"\n","    Formata a coluna de data e adiciona uma coluna de mês ao DataFrame.\n","\n","    Parameters:\n","    - df (pd.DataFrame): O DataFrame a ser formatado.\n","\n","    Returns:\n","    - df_formatado (pd.DataFrame): O DataFrame resultante após a formatação da data.\n","\n","    Example:\n","    >>> df = pd.DataFrame({'date': ['2022-01-01', '2022-02-01', '2022-03-01'],\n","    ...                    'close': [100, 105, 98],\n","    ...                    'volume': [1000, 1200, 900],\n","    ...                    'market_cap': [5000, 5500, 4800],\n","    ...                    'ticker': ['AAPL', 'AAPL', 'AAPL']})\n","    >>> df_formatado = formatar_data(df)\n","    >>> print(df_formatado.head())\n","         date  close  volume  market_cap ticker      month\n","    0 2022-01-01    100    1000        5000   AAPL 2022-01-01\n","    1 2022-02-01    105    1200        5500   AAPL 2022-02-01\n","    2 2022-03-01     98     900        4800   AAPL 2022-03-01\n","    \"\"\"\n","    # Criar uma cópia do DataFrame para evitar modificações indesejadas\n","    df_copy = df.reset_index().copy()\n","\n","    # Adicionar uma coluna de mês ao DataFrame\n","    df_copy['month'] = df_copy['date'].dt.to_period('M').dt.to_timestamp()\n","\n","    return df_copy"],"metadata":{"id":"dmbJf_sLqudO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calcular_medias_por_mes(df):\n","    \"\"\"\n","    Calcula médias por mês e ticker a partir de um DataFrame.\n","\n","    Parameters:\n","    - df (pd.DataFrame): O DataFrame contendo os dados a serem agregados.\n","\n","    Returns:\n","    - df_agregado (pd.DataFrame): O DataFrame resultante após a agregação por mês e ticker.\n","\n","    Example:\n","    >>> df = pd.DataFrame({'date': ['2022-01-01', '2022-01-01', '2022-02-01', '2022-02-01'],\n","    ...                    'close': [100, 110, 105, 108],\n","    ...                    'volume': [1000, 1200, 900, 950],\n","    ...                    'market_cap': [5000, 5500, 4800, 5200],\n","    ...                    'ticker': ['AAPL', 'AAPL', 'AAPL', 'AAPL']})\n","    >>> df_agregado = calcular_medias_por_mes(df)\n","    >>> print(df_agregado.head())\n","         month ticker  close_mean  volume_mean  market_cap_mean\n","    0 2022-01-01   AAPL       105.0       1100.0           5250.0\n","    1 2022-02-01   AAPL       106.5        925.0           5000.0\n","    \"\"\"\n","    # Agrupar por mês e ticker, calculando as médias\n","    df_agregado = df.groupby([\"month\", \"ticker\"]).agg(\n","        close_mean=(\"close\", \"mean\"),\n","        volume_mean=(\"volume\", \"mean\"),\n","        market_cap_mean=(\"market_cap\", \"mean\")\n","    ).reset_index()\n","\n","    return df_agregado"],"metadata":{"id":"4DdJ1K4lqyL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pivotar_dataframe(df):\n","    \"\"\"\n","    Realiza a pivotagem de um DataFrame.\n","\n","    Parameters:\n","    - df (pd.DataFrame): O DataFrame a ser pivotado.\n","\n","    Returns:\n","    - df_pivotado (pd.DataFrame): O DataFrame resultante após a pivotagem.\n","\n","    Example:\n","    >>> df = pd.DataFrame({'month': ['2022-01-01', '2022-02-01'],\n","    ...                    'ticker': ['AAPL', 'AAPL'],\n","    ...                    'close_mean': [105.0, 106.5]})\n","    >>> df_pivotado = pivotar_dataframe(df)\n","    >>> print(df_pivotado.head())\n","           month   AAPL\n","    0 2022-01-01  105.0\n","    1 2022-02-01  106.5\n","    \"\"\"\n","    # Pivotar o DataFrame\n","    df_pivotado = df.pivot_table(index='month', columns='ticker', values='close_mean')\n","\n","    # Tornar todos os nomes de coluna como string\n","    df_pivotado.columns = df_pivotado.columns.astype(str)\n","\n","    # Preencher valores ausentes com 0\n","    df_pivotado = df_pivotado.fillna(0)\n","\n","    # Resetar o índice e remover o nome da coluna\n","    df_pivotado = df_pivotado.reset_index()\n","    df_pivotado.columns.name = None\n","\n","    return df_pivotado"],"metadata":{"id":"zOMvWu3LrKHA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Metrics"],"metadata":{"id":"sUZwvG0stH4m"}},{"cell_type":"code","source":["def processar_e_salvar_params(gold_save_path, filename, df, build_best_params=False):\n","    \"\"\"\n","    Processa os parâmetros para cada ticker no DataFrame df usando auto_arima e salva os resultados em um arquivo JSON.\n","\n","    Parameters:\n","    - gold_save_path (str): Caminho onde o arquivo será salvo.\n","    - filename (str): Nome do arquivo a ser salvo.\n","    - df (pandas.DataFrame): DataFrame contendo os dados para os quais os parâmetros serão calculados.\n","    - build_best_params (bool, optional): Indica se deve criar um novo arquivo de parâmetros ou apenas verificar se o arquivo já existe.\n","                                          Se True, cria um novo arquivo; se False (padrão), verifica a existência do arquivo.\n","\n","    Returns:\n","    None\n","\n","    Example:\n","    processar_e_salvar_params(gold_save_path, \"best_params_dict.json\", df, build_best_params=False)\n","    \"\"\"\n","\n","    # Verificando se o arquivo já existe\n","    if os.path.exists(gold_save_path) and not build_best_params:\n","        print(f'O conjunto de parâmetros para cada ticker {filename} já existe. Não foi criado um novo arquivo.')\n","    else:\n","        best_params_dict = {}\n","        for tk in tqdm(df.columns, desc=f\"Processando parâmetros para {tk}\"):\n","            model = auto_arima(df[tk].values, seasonal=True, m=12, D=1, start_P=1, start_Q=1, max_P=3, max_Q=3, information_criterion='aic', trace=False, error_action='ignore', stepwise=True)\n","            best_order = model.order\n","            best_seasonal_order = model.seasonal_order\n","            best_params_dict[tk] = {\"best_order\": model.order, \"best_seasonal_order\": model.seasonal_order}\n","\n","        # Salvando o dicionário usando json\n","        with open(gold_save_path, 'w') as arquivo:\n","            json.dump(best_params_dict, arquivo)\n","        print(f'Dicionário salvo em {gold_save_path}')\n","\n","# Exemplo de chamada da função\n","processar_e_salvar_params(gold_save_path, \"best_params_dict.json\", df, build_best_params=False)"],"metadata":{"id":"I87aQ5jKtKJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def carregar_dicionario_params(caminho_arquivo):\n","    \"\"\"\n","    Carrega um dicionário a partir de um arquivo JSON.\n","\n","    Parameters:\n","    - caminho_arquivo (str): O caminho para o arquivo JSON a ser carregado.\n","\n","    Returns:\n","    - dict: O dicionário carregado a partir do arquivo JSON.\n","\n","    Example:\n","    >>> best_params_dict = carregar_dicionario(\"../content/drive/MyDrive/01 - Projetos/crypto_forecast/gold/df_gold.parquet\")\n","    >>> print(best_params_dict)\n","    {'BTC': {'best_order': (1, 1, 1), 'best_seasonal_order': (0, 1, 1, 12)}, ...}\n","    \"\"\"\n","    with open(caminho_arquivo, 'r') as arquivo:\n","        dicionario_carregado = json.load(arquivo)\n","\n","    return dicionario_carregado"],"metadata":{"id":"Eu6_b06lt_0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to-do: MAPE dos modelos"],"metadata":{"id":"TBqstCHLtXIT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Forecast"],"metadata":{"id":"BgFuj1DstKoG"}},{"cell_type":"code","source":["def gerar_previsoes_sarimax(df, best_params_dict, n_periods_out_of_sample=6):\n","    \"\"\"\n","    Gera previsões utilizando o modelo SARIMAX para várias séries temporais.\n","\n","    Parameters:\n","    - df (pd.DataFrame): O DataFrame contendo as séries temporais.\n","    - best_params_dict (dict): Um dicionário contendo os melhores parâmetros para cada série.\n","    - n_periods_out_of_sample (int): O número de períodos para prever out-of-sample.\n","\n","    Returns:\n","    - fs_df (pd.DataFrame): Um DataFrame contendo as previsões, intervalos de confiança e informações adicionais.\n","\n","    Example:\n","    >>> df = ...  # Seu DataFrame com séries temporais\n","    >>> best_params_dict = {'BTC': {'best_order': (1, 1, 1), 'best_seasonal_order': (0, 1, 1, 12)}}\n","    >>> fs_df = gerar_previsoes_sarimax(df, best_params_dict, n_periods_out_of_sample=6)\n","    >>> print(fs_df.head())\n","             close_mean  lower_bound  upper_bound ticker  type\n","    2023-01-01    ...         ...         ...       BTC  PRED\n","    ...           ...         ...         ...       ...  ...\n","    \"\"\"\n","    fs_df = pd.DataFrame()\n","\n","    print(\"Gerando Previsões SARIMAX\")\n","    for tk, params in tqdm(best_params_dict.items()):\n","\n","        print(f\" Prevendo valores para {tk}\")\n","        BEST_ORDER = params[\"best_order\"]\n","        BEST_SEASONAL_ORDER = params[\"best_seasonal_order\"]\n","\n","        model = SARIMAX(df[f'{tk}'], order=BEST_ORDER, seasonal_order=BEST_SEASONAL_ORDER)\n","        res = model.fit()\n","\n","        fs = res.get_forecast(steps=n_periods_out_of_sample)\n","        fs_values = fs.predicted_mean\n","        fs_lower_bound = fs.conf_int().iloc[:, 0]\n","        fs_upper_bound = fs.conf_int().iloc[:, 1]\n","\n","        #  fs_values_df = pd.DataFrame(fs_values.values, columns=[f'close_mean'], index=fs_values.index)\n","        fs_values_df = fs_values.reset_index()\n","        fs_values_df[\"lower_bound\"] = np.where(fs_lower_bound.values < 0, fs_lower_bound.values, 0)\n","        fs_values_df[\"upper_bound\"] = fs_upper_bound.values\n","        fs_values_df[\"ticker\"] = tk\n","        fs_values_df[\"type\"] = \"PRED\"\n","        fs_values_df[\"model\"] = \"SARIMA\"\n","\n","        fs_df = fs_df.append(fs_values_df)\n","\n","    fs_df.rename(columns={\"predicted_mean\": \"close_mean\"}, inplace=True)\n","    fs_df.set_index(\"index\", inplace=True)\n","    return fs_df"],"metadata":{"id":"uLFTU0cGtMi4"},"execution_count":null,"outputs":[]}]}